{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab1823d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, to_timestamp, isnan, when, count, hour, day,month, year, weekday, udf\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "038f439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('uber_data_processing').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41cc31f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.csv('uber_data_2016.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c2c9767",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.withColumn('tpep_pickup_datetime',to_timestamp('tpep_pickup_datetime','dd-MM-yyyy HH:mm'))\n",
    "df=df.withColumn('tpep_dropoff_datetime',to_timestamp('tpep_pickup_datetime','dd-MM-yyyy HH:mm'))\n",
    "df=df.na.drop(how='all')\n",
    "df=df.na.drop(how='all',subset=['VendorID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5859486f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------------+---------------+----------+------------------+-----------------+----------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|pickup_longitude|pickup_latitude|RatecodeID|store_and_fwd_flag|dropoff_longitude|dropoff_latitude|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------------+---------------+----------+------------------+-----------------+----------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
      "|       0|                   0|                    0|              0|            0|               0|              0|         0|                 0|                0|               0|           0|          0|    0|      0|         0|           0|                    0|           0|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------------+---------------+----------+------------------+-----------------+----------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check the count of Null values per column\n",
    "df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f45fe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_dim = df.selectExpr(\n",
    "    'tpep_pickup_datetime',\n",
    "    'tpep_dropoff_datetime',\n",
    "    'hour(tpep_pickup_datetime) as pickup_hour',\n",
    "    'day(tpep_pickup_datetime) as pickup_day',\n",
    "    'month(tpep_pickup_datetime) as pickup_month',\n",
    "    'year(tpep_pickup_datetime) as pickup_year',\n",
    "    'weekday(tpep_pickup_datetime) as pickup_weekday',\n",
    "    'hour(tpep_dropoff_datetime) as dropoff_hour',\n",
    "    'day(tpep_dropoff_datetime) as dropoff_day',\n",
    "    'month(tpep_dropoff_datetime) as dropoff_month',\n",
    "    'year(tpep_dropoff_datetime) as dropoff_year',\n",
    "    'weekday(tpep_dropoff_datetime) as dropoff_weekday',\n",
    "    'monotonically_increasing_id() as datetime_id'\n",
    ")\n",
    "datetime_dim=datetime_dim.select('datetime_id','tpep_pickup_datetime','pickup_hour','pickup_day','pickup_month','pickup_year','pickup_weekday','tpep_dropoff_datetime','dropoff_hour','dropoff_day','dropoff_month','dropoff_year','dropoff_weekday')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6168ab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_dim=df.selectExpr('monotonically_increasing_id() as location_id','pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "542e99a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "payment_type_dim=df.selectExpr('monotonically_increasing_id() as payment_type_id', 'payment_type')\n",
    "rate_code_dim=df.selectExpr('monotonically_increasing_id() as rate_code_id', 'RateCodeID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55c2cea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------------+-------------+------------------+-----------+-----+-------+----------+------------+---------------------+------------+-----------+--------------------+-----------+----------+------------+-----------+--------------+---------------------+------------+-----------+-------------+------------+---------------+-----------+----------------+---------------+-----------------+----------------+------------+----------+---------------+------------+\n",
      "|trip_id|VendorID|passenger_count|trip_distance|store_and_fwd_flag|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|datetime_id|tpep_pickup_datetime|pickup_hour|pickup_day|pickup_month|pickup_year|pickup_weekday|tpep_dropoff_datetime|dropoff_hour|dropoff_day|dropoff_month|dropoff_year|dropoff_weekday|location_id|pickup_longitude|pickup_latitude|dropoff_longitude|dropoff_latitude|rate_code_id|RateCodeID|payment_type_id|payment_type|\n",
      "+-------+--------+---------------+-------------+------------------+-----------+-----+-------+----------+------------+---------------------+------------+-----------+--------------------+-----------+----------+------------+-----------+--------------+---------------------+------------+-----------+-------------+------------+---------------+-----------+----------------+---------------+-----------------+----------------+------------+----------+---------------+------------+\n",
      "|      0|       1|              1|          2.5|                 N|        9.0|  0.5|    0.5|      2.05|         0.0|                  0.3|       12.35|          0| 2016-03-01 00:00:00|          0|         1|           3|       2016|             1|  2016-03-01 00:00:00|           0|          1|            3|        2016|              1|          0|    -73.97674561|    40.76515198|     -74.00426483|     40.74612808|           0|         1|              0|           1|\n",
      "|      1|       1|              1|          2.9|                 N|       11.0|  0.5|    0.5|      3.05|         0.0|                  0.3|       15.35|          1| 2016-03-01 00:00:00|          0|         1|           3|       2016|             1|  2016-03-01 00:00:00|           0|          1|            3|        2016|              1|          1|    -73.98348236|    40.76792526|      -74.0059433|     40.73316574|           1|         1|              1|           1|\n",
      "|      2|       2|              2|        19.98|                 N|       54.5|  0.5|    0.5|       8.0|         0.0|                  0.3|        63.8|          2| 2016-03-01 00:00:00|          0|         1|           3|       2016|             1|  2016-03-01 00:00:00|           0|          1|            3|        2016|              1|          2|    -73.78202057|    40.64480972|     -73.97454071|     40.67576981|           2|         1|              2|           1|\n",
      "|      3|       2|              3|        10.78|                 N|       31.5|  0.0|    0.5|      3.78|        5.54|                  0.3|       41.62|          3| 2016-03-01 00:00:00|          0|         1|           3|       2016|             1|  2016-03-01 00:00:00|           0|          1|            3|        2016|              1|          3|    -73.86341858|    40.76981354|     -73.96965027|     40.75776672|           3|         1|              3|           1|\n",
      "|      4|       2|              5|        30.43|                 N|       98.0|  0.0|    0.0|       0.0|        15.5|                  0.3|       113.8|          4| 2016-03-01 00:00:00|          0|         1|           3|       2016|             1|  2016-03-01 00:00:00|           0|          1|            3|        2016|              1|          4|    -73.97174072|    40.79218292|      -74.1771698|      40.6950531|           4|         3|              4|           1|\n",
      "|      5|       2|              5|         5.92|                 N|       23.5|  1.0|    0.5|      5.06|         0.0|                  0.3|       30.36|          5| 2016-03-01 00:00:00|          0|         1|           3|       2016|             1|  2016-03-01 00:00:00|           0|          1|            3|        2016|              1|          5|    -74.01719666|     40.7053833|     -73.97807312|      40.7557869|           5|         1|              5|           1|\n",
      "|      6|       2|              6|         5.72|                 N|       23.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        24.3|          6| 2016-03-01 00:00:00|          0|         1|           3|       2016|             1|  2016-03-01 00:00:00|           0|          1|            3|        2016|              1|          6|    -73.99458313|    40.72784805|              0.0|             0.0|           6|         1|              6|           2|\n",
      "|      7|       1|              1|          6.2|                 N|       20.5|  0.5|    0.5|       0.0|         0.0|                  0.3|        21.8|          7| 2016-03-01 00:00:00|          0|         1|           3|       2016|             1|  2016-03-01 00:00:00|           0|          1|            3|        2016|              1|          7|    -73.78877258|    40.64775848|     -73.82920837|     40.71234512|           7|         1|              7|           3|\n",
      "|      8|       1|              1|          0.7|                 N|        5.5|  0.5|    0.5|       2.0|         0.0|                  0.3|         8.8|          8| 2016-03-01 00:00:00|          0|         1|           3|       2016|             1|  2016-03-01 00:00:00|           0|          1|            3|        2016|              1|          8|    -73.95822144|    40.76464081|     -73.96789551|     40.76290131|           8|         1|              8|           1|\n",
      "|      9|       2|              3|         7.18|                 N|       23.5|  0.5|    0.5|       3.2|         0.0|                  0.3|        28.0|          9| 2016-03-01 00:00:00|          0|         1|           3|       2016|             1|  2016-03-01 00:00:00|           0|          1|            3|        2016|              1|          9|    -73.98577881|    40.74119186|      -73.9463501|     40.79787827|           9|         1|              9|           1|\n",
      "|     10|       2|              2|         0.54|                 N|        4.0|  0.5|    0.5|       0.0|         0.0|                  0.3|         5.3|         10| 2016-03-01 00:00:00|          0|         1|           3|       2016|             1|  2016-03-01 00:00:00|           0|          1|            3|        2016|              1|         10|    -73.98842621|    40.76416016|     -73.99239349|     40.75822449|          10|         1|             10|           2|\n",
      "|     11|       1|              1|          1.7|                 N|        8.0|  0.5|    0.5|       0.0|         0.0|                  0.3|         9.3|         11| 2016-03-01 00:00:00|          0|         1|           3|       2016|             1|  2016-03-01 00:00:00|           0|          1|            3|        2016|              1|         11|    -73.96981812|    40.79742813|     -73.94377136|      40.7961998|          11|         1|             11|           2|\n",
      "|     12|       1|              1|          1.1|                 N|        5.5|  0.5|    0.5|       2.2|         0.0|                  0.3|         9.0|         12| 2016-03-01 00:00:00|          0|         1|           3|       2016|             1|  2016-03-01 00:00:00|           0|          1|            3|        2016|              1|         12|    -73.95380402|     40.7881279|     -73.97154999|     40.79523849|          12|         1|             12|           1|\n",
      "|     13|       2|              1|          2.1|                 N|        9.0|  0.5|    0.5|      2.06|         0.0|                  0.3|       12.36|         13| 2016-03-01 00:00:00|          0|         1|           3|       2016|             1|  2016-03-01 00:00:00|           0|          1|            3|        2016|              1|         13|    -73.97608948|    40.75217056|     -73.98744965|     40.77078247|          13|         1|             13|           1|\n",
      "|     14|       2|              1|         8.54|                 N|       27.0|  0.5|    0.5|      5.66|         0.0|                  0.3|       33.96|         14| 2016-03-01 00:00:00|          0|         1|           3|       2016|             1|  2016-03-01 00:00:00|           0|          1|            3|        2016|              1|         14|    -74.00206757|    40.71912003|     -73.95211792|     40.81124115|          14|         1|             14|           1|\n",
      "|     15|       2|              1|          2.0|                 N|        8.5|  0.5|    0.5|       2.0|         0.0|                  0.3|        11.8|         15| 2016-03-01 00:00:00|          0|         1|           3|       2016|             1|  2016-03-01 00:00:00|           0|          1|            3|        2016|              1|         15|    -74.00672913|    40.73071671|     -74.01704407|     40.70936584|          15|         1|             15|           1|\n",
      "|     16|       1|              1|          3.2|                 N|       11.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        12.3|         16| 2016-03-01 00:00:00|          0|         1|           3|       2016|             1|  2016-03-01 00:00:00|           0|          1|            3|        2016|              1|         16|    -74.00661469|     40.7166214|     -73.99010468|     40.75605011|          16|         1|             16|           2|\n",
      "|     17|       2|              1|         1.59|                 N|        8.0|  0.5|    0.5|      1.86|         0.0|                  0.3|       11.16|         17| 2016-03-01 00:00:00|          0|         1|           3|       2016|             1|  2016-03-01 00:00:00|           0|          1|            3|        2016|              1|         17|    -73.98226929|    40.77061844|     -73.96874237|     40.75503922|          17|         1|             17|           1|\n",
      "|     18|       2|              3|        16.81|                 N|       52.0|  0.0|    0.5|       8.0|        5.54|                  0.3|       66.34|         18| 2016-03-01 00:00:00|          0|         1|           3|       2016|             1|  2016-03-01 00:00:00|           0|          1|            3|        2016|              1|         18|    -73.79238892|    40.64503098|     -73.98628998|     40.75851822|          18|         2|             18|           1|\n",
      "|     19|       1|              2|          0.5|                 N|        4.5|  0.5|    0.5|      1.15|         0.0|                  0.3|        6.95|         19| 2016-03-01 00:00:00|          0|         1|           3|       2016|             1|  2016-03-01 00:00:00|           0|          1|            3|        2016|              1|         19|    -73.98378754|    40.73189163|     -73.97581482|     40.72851944|          19|         1|             19|           1|\n",
      "+-------+--------+---------------+-------------+------------------+-----------+-----+-------+----------+------------+---------------------+------------+-----------+--------------------+-----------+----------+------------+-----------+--------------+---------------------+------------+-----------+-------------+------------+---------------+-----------+----------------+---------------+-----------------+----------------+------------+----------+---------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fact_table=df.selectExpr('monotonically_increasing_id() as trip_id','VendorID','passenger_count','trip_distance','store_and_fwd_flag','fare_amount','extra',\n",
    "                         'mta_tax','tip_amount','tolls_amount','improvement_surcharge','total_amount')\n",
    "\n",
    "all_table = fact_table \\\n",
    "    .join(datetime_dim, fact_table['trip_id'] == datetime_dim['datetime_id'], how='left') \\\n",
    "    .join(location_dim, fact_table['trip_id'] == location_dim['location_id'], how='left') \\\n",
    "    .join(rate_code_dim, fact_table['trip_id'] == rate_code_dim['rate_code_id'], how='left') \\\n",
    "    .join(payment_type_dim, fact_table['trip_id'] == payment_type_dim['payment_type_id'], how= 'left')\n",
    "all_table.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4165fbf",
   "metadata": {},
   "source": [
    "# Extra Data manipulation for any further analysis \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ba98b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find trip duration in seconds, minutes & hours  ## With \"withColumn\" function\n",
    "df=df.withColumn('trip_duration_in_seconds',(F.unix_timestamp('tpep_dropoff_datetime') - F.unix_timestamp('tpep_pickup_datetime')))\n",
    "df=df.withColumn('trip_duration_minutes',F.col('trip_duration_in_seconds')/60)\n",
    "df=df.withColumn('trip_duration_hours',F.col('trip_duration_in_seconds')/3600)\n",
    "\n",
    "#Find trip distance in meters, trip distance per passenger in meters, trip distance per passenger in kms  ##with \"selectExpr\"function\n",
    "df= df.withColumn('trip_distance_in_meters',F.col('trip_distance')*1000) \\\n",
    "    .withColumn('distance_per_pessenger',(F.col('trip_distance_in_meters')/F.col('passenger_count'))) \\\n",
    "    .withColumn('distance_per_pessenger_in_kms',F.col('distance_per_pessenger')/1000)\n",
    "df_extra=df.selectExpr(\n",
    "    \"trip_distance * 1000 as trip_distance_in_meters\",\n",
    "    \"(trip_distance * 1000) / passenger_count as distance_per_pessenger\",\n",
    "    \"((trip_distance * 1000) / passenger_count) / 1000 as distance_per_pessenger_in_kms\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "839db837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pandas_df=all_table.toPandas()\n",
    "pandas_df.to_csv('all_tables.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0e0d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Use below code for AWS glue to import the raw data from AWS S3 and Write the transformed data into AWS Redshift \n",
    "def MyTransform(glueContext, dfc) -> DynamicFrame:\n",
    "    from pyspark.sql import SparkSession\n",
    "    from awsglue.dynamicframe import DynamicFrame\n",
    "    from pyspark.sql.functions import col, to_timestamp, isnan, when, count, hour, day,month, year, weekday, udf, to_timestamp, monotonically_increasing_id\n",
    "    from pyspark.sql import functions as F\n",
    "    from pyspark.sql.types import StringType\n",
    "\n",
    "    \n",
    "    spark = glueContext.spark_session\n",
    "\n",
    "    \n",
    "    s3_input_path = 's3://uber-project/Uber_Raw_Data/uber_data_2016.csv'\n",
    "    \n",
    "    \n",
    "    df = spark.read.csv(s3_input_path, header=True, inferSchema=True)\n",
    "    \n",
    "    \n",
    "    df.printSchema()\n",
    "    \n",
    "    \n",
    "    datetime_dim = df.selectExpr(\n",
    "    'tpep_pickup_datetime',\n",
    "    'tpep_dropoff_datetime',\n",
    "    'hour(tpep_pickup_datetime) as pickup_hour',\n",
    "    'day(tpep_pickup_datetime) as pickup_day',\n",
    "    'month(tpep_pickup_datetime) as pickup_month',\n",
    "    'year(tpep_pickup_datetime) as pickup_year',\n",
    "    'weekday(tpep_pickup_datetime) as pickup_weekday',\n",
    "    'hour(tpep_dropoff_datetime) as dropoff_hour',\n",
    "    'day(tpep_dropoff_datetime) as dropoff_day',\n",
    "    'month(tpep_dropoff_datetime) as dropoff_month',\n",
    "    'year(tpep_dropoff_datetime) as dropoff_year',\n",
    "    'weekday(tpep_dropoff_datetime) as dropoff_weekday',\n",
    "    'monotonically_increasing_id() as datetime_id'\n",
    "    )\n",
    "    datetime_dim=datetime_dim.select('datetime_id','tpep_pickup_datetime','pickup_hour','pickup_day','pickup_month','pickup_year','pickup_weekday','tpep_dropoff_datetime','dropoff_hour','dropoff_day','dropoff_month','dropoff_year','dropoff_weekday')\n",
    "\n",
    "    location_dim=df.selectExpr('monotonically_increasing_id() as location_id','pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude')\n",
    "    payment_type_dim=df.selectExpr('monotonically_increasing_id() as payment_type_id', 'payment_type')\n",
    "    rate_code_dim=df.selectExpr('monotonically_increasing_id() as rate_code_id', 'RateCodeID')\n",
    "    \n",
    "    fact_table=df.selectExpr('monotonically_increasing_id() as trip_id','VendorID','passenger_count','trip_distance','store_and_fwd_flag','fare_amount','extra',\n",
    "                         'mta_tax','tip_amount','tolls_amount','improvement_surcharge','total_amount')\n",
    "                         \n",
    "\n",
    "    # Convert Spark DataFrame to Glue DynamicFrame\n",
    "    dynamic_frame = DynamicFrame.fromDF(df, glueContext, \"dynamic_frame\")\n",
    "    datetime_dynamic_frame = DynamicFrame.fromDF(datetime_dim, glueContext, \"datetime_dynamic_frame\")\n",
    "    location_dynamic_frame = DynamicFrame.fromDF(location_dim, glueContext, \"location_dynamic_frame\")\n",
    "    payment_type_dynamic_frame = DynamicFrame.fromDF(payment_type_dim, glueContext, \"payment_type_dynamic_frame\")\n",
    "    rate_code_dynamic_frame = DynamicFrame.fromDF(rate_code_dim, glueContext, \"rate_code_dynamic_frame\")\n",
    "    fact_dynamic_frame = DynamicFrame.fromDF(fact_table, glueContext, \"fact_dynamic_frame\")\n",
    "    \n",
    "    #Define the redshift connection ---------- Modify below details as per your configuration\n",
    "    redshift_options = {\n",
    "        \"url\": \"jdbc:redshift://<redshift-cluster-url>:<port>/<database>\",\n",
    "        \"user\": \"<Enter your redshift username>\",\n",
    "        \"password\": \"<Enter your redshift password>\",\n",
    "        \"dbtable\": \"<redshift-schema-name>.<fact_table>\",  \n",
    "        \"aws_iam_role\": \"<iam-role-arn>\"  \n",
    "    }\n",
    "    \n",
    "    \n",
    "     # Write the fact table to Redshift\n",
    "    redshift_fact_options = redshift_options.copy()\n",
    "    redshift_fact_options[\"dbtable\"] = \"<redshift-schema-name>.fact_table\"\n",
    "    glueContext.write_dynamic_frame.from_options(\n",
    "        fact_dynamic_frame,\n",
    "        connection_type=\"redshift\",\n",
    "        connection_options=redshift_fact_options\n",
    "    )\n",
    "\n",
    "    # Write the datetime dimension table to Redshift\n",
    "    redshift_datetime_options = redshift_options.copy()\n",
    "    redshift_datetime_options[\"dbtable\"] = \"<redshift-schema-name>.datetime_dim\"\n",
    "    glueContext.write_dynamic_frame.from_options(\n",
    "        datetime_dynamic_frame,\n",
    "        connection_type=\"redshift\",\n",
    "        connection_options=redshift_datetime_options\n",
    "    )\n",
    "\n",
    "    \n",
    "    redshift_location_options = redshift_options.copy()\n",
    "    redshift_location_options[\"dbtable\"] = \"<redshift-schema-name>.location_dim\"\n",
    "    glueContext.write_dynamic_frame.from_options(\n",
    "        location_dynamic_frame,\n",
    "        connection_type=\"redshift\",\n",
    "        connection_options=redshift_location_options\n",
    "    )\n",
    "\n",
    "   \n",
    "    redshift_payment_type_options = redshift_options.copy()\n",
    "    redshift_payment_type_options[\"dbtable\"] = \"<redshift-schema-name>.payment_type_dim\"\n",
    "    glueContext.write_dynamic_frame.from_options(\n",
    "        payment_type_dynamic_frame,\n",
    "        connection_type=\"redshift\",\n",
    "        connection_options=redshift_payment_type_options\n",
    "    )\n",
    "\n",
    "    \n",
    "    redshift_rate_code_options = redshift_options.copy()\n",
    "    redshift_rate_code_options[\"dbtable\"] = \"<redshift-schema-name>.rate_code_dim\"\n",
    "    glueContext.write_dynamic_frame.from_options(\n",
    "        rate_code_dynamic_frame,\n",
    "        connection_type=\"redshift\",\n",
    "        connection_options=redshift_rate_code_options\n",
    "    )\n",
    "\n",
    "    \n",
    "    \n",
    "    # Return the DynamicFrame (for Redshift, you return a single DynamicFrame)\n",
    "    #After all the writes to Redshift are completed, the function returns the fact_dynamic_frame. This is done in case the fact table data is needed further in the pipeline or for debugging purposes. If you donâ€™t need to use the fact_dynamic_frame again, this return statement can be skipped.\n",
    "    return dynamic_frame\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
